{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Il faut l'exécuter en entier d'un coup. L'interface graphique est ensuite accessible à cette adresse http://127.0.0.1:8050/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des tables et des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "import requests\n",
    "from dash_table import DataTable\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from haversine import haversine, Unit\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_table\n",
    "from dash.dependencies import Input, Output, State\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from datetime import date\n",
    "\n",
    "tab= pd.read_csv('full_paris_def.csv')\n",
    "df_gares=pd.read_csv('gares-idf.csv',';')\n",
    "\n",
    "def formatage(txt):\n",
    "    # Cette fonction sert à séparer latitude et longitude exprimés sous la forme 48.9876,2.0986 \n",
    "    for i in range(len(txt)):\n",
    "        if txt[i]==',':\n",
    "            return(i)\n",
    "        \n",
    "    \n",
    "def format_prix(prix): \n",
    "    # Cette fonction prend en entrée un prix et renvoi le prix écrit de façon lisible ex: X XXX XXX €\n",
    "    prix=int(prix)\n",
    "    s = str(prix)\n",
    "    txt=''\n",
    "    for i in range(len(s)):\n",
    "        if (len(s)-i)%3==0:\n",
    "            txt=s[i]+' '+txt\n",
    "        else:\n",
    "            txt=s[i]+txt\n",
    "    return(txt[::-1]+\" €\") \n",
    "\n",
    "\n",
    "# Ce passage du code permet de mettre la table df_gares dans un format lisible (en séparant latitude et longitude)\n",
    "lat=[]\n",
    "lon=[]\n",
    "for i in range(len(df_gares)):\n",
    "    coord=df_gares['geo_point_2d'].iloc[i]\n",
    "    j=formatage(coord)\n",
    "    lat.append(float(coord[:j]))\n",
    "    lon.append(float(coord[j+1:]))\n",
    "df_gares[\"lat\"]=lat\n",
    "df_gares[\"lon\"]=lon\n",
    "\n",
    "#On récupère la table contenant les données sur les marchés\n",
    "df_marches=pd.read_csv('marches-decouverts.csv',';')\n",
    "df_marches=df_marches[df_marches['Produit']=='Alimentaire']\n",
    "#On se restreint aux marchés alimentaires\n",
    "df_marches=df_marches.drop(columns=['Identifiant marché','Nom complet','Produit','Arrondissement','Localisation','LUNDI','MARDI','MERCREDI','JEUDI','VENDREDI','SAMEDI','DIMANCHE','Secteur','Gestionnaire','Heure début en semaine','Heure fin en semaine','Heure début le samedi','Heure début le dimanche','Heure fin le dimanche','geo_shape','Linéaire commercial','Heure fin le samedi'])\n",
    "lat=[]\n",
    "lon=[]\n",
    "for i in range(len(df_marches)):\n",
    "    coord=df_marches['geo_point_2d'].iloc[i]\n",
    "    j=formatage(coord)\n",
    "    \n",
    "    lon.append(float(coord[:j])),\n",
    "    lat.append(float(coord[j+1:]))\n",
    "df_marches['lat']=lat\n",
    "df_marches['lon']=lon\n",
    "# Comme pour les gares, on met les coordonnés géographiques dans un format acceptable\n",
    "\n",
    "\n",
    "\n",
    "# Ce passage permet de retrouver les données relatives au quadrillage qui divise Paris et qui permet de localiser les biens\n",
    "N=max(tab['vert'])\n",
    "step_lat=(max(tab['latitude'])-min(tab['latitude']))/N\n",
    "step_lon=(max(tab['longitude'])-min(tab['longitude']))/N\n",
    "min_lat=min(tab['latitude'])\n",
    "min_lon=min(tab['longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bon_format(nbre_pieces, surface_m_2):\n",
    "    #Fonction pour mettre au bon format les données fournies par l'utilisateur\n",
    "    return np.array([nbre_pieces, surface_m_2]).reshape(-1, 2)\n",
    "\n",
    "def pred_secteurs(dataset, bien):\n",
    "    dataset=dataset.drop(columns=['Prixm2', 'Unnamed: 0','date_mutation','label', 'code_postal', 'surface_terrain', 'longitude', 'latitude', 'groupes', 'vert', 'horiz'])\n",
    "    Y = dataset.valeur_fonciere #On isole la valeur_fonciere\n",
    "    #On retire la valeur_fonciere du dataset pour faire la régression linéaire\n",
    "    dataset = dataset.loc[:,dataset.columns.difference(['valeur_fonciere'])]\n",
    "    #On lance une régression linéaire multiple, qu'on fit ensuite\n",
    "    model_LinRegMul = LinearRegression()\n",
    "    print(np.shape(dataset))\n",
    "    print(np.shape(Y))\n",
    "    model_LinRegMul.fit(dataset, Y)\n",
    "    #On mesure sa précision et on affiche ses coefficients\n",
    "    precision = model_LinRegMul.score(dataset, Y)\n",
    "    print(model_LinRegMul.coef_)\n",
    "    print(precision*100) #On affiche le R²\n",
    "    #On prédit la valeur du bien \"bien\", et on la retourne\n",
    "    prediction = model_LinRegMul.predict(bien)\n",
    "    return(prediction)\n",
    "\n",
    "def predict_temp(tab, date_prix):\n",
    "    #On supprime les colonnes inutiles\n",
    "    tab2=tab.drop(columns=['valeur_fonciere',\n",
    "       'code_postal', 'surface_reelle_bati', 'nombre_pieces_principales',\n",
    "       'surface_terrain', 'longitude', 'latitude','groupes', 'vert', 'horiz', 'label', 'Unnamed: 0'])\n",
    "    \n",
    "    #On transforme les valeurs de la colonne date_mutation en des objets \"datetime\"\n",
    "    \n",
    "    tab2['date_mutation'] = pd.to_datetime(tab2['date_mutation'],dayfirst=True)\n",
    "    \n",
    "    #On trie par date de vente croissante, et on met la date en index du dataframe tab\n",
    "    \n",
    "    tab2.sort_values('date_mutation',inplace=True)\n",
    "    tab2.set_index('date_mutation',inplace=True)\n",
    "    \n",
    "    #Prédictions avec ARIMA : on fit un ARIMA(5,1,0) sur nos données,\n",
    "    #et on prédit le prix moyen du m² à la date souhaitée, qu'on retourne dans la variable output\n",
    "    \n",
    "    model = ARIMA(tab2, order=(0,1,2))\n",
    "    model_fit = model.fit()\n",
    "    dayss = (date_prix - date(2021, 1, 1)).days\n",
    "    output = model_fit.forecast(dayss)[0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions pour récupérer les commodités à proximité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordo(num,typerue,nomrue,cp):\n",
    "    #Cette fonction prend en entrée une adresse et renvoi Latitude, Longitude et le nom du lieu\n",
    "    url='https://api-adresse.data.gouv.fr/search/?q='+str(num)+\"+\"+typerue+\"+\"+nomrue+\"+\"+str(cp)\n",
    "    Place=requests.get(url).json()\n",
    "    # On interroge l'API d'adresses du Gouvernement qui renvoi un dictionnaire au format json\n",
    "    Lon=Place['features'][0]['geometry']['coordinates'][0]\n",
    "    Lat=Place['features'][0]['geometry']['coordinates'][1]\n",
    "    Name=Place['features'][0]['properties']['label']\n",
    "    return(Lat,Lon,Name)\n",
    "\n",
    "\n",
    "def next_gares(lat,lon):\n",
    "    # Cette fonction  prend en entrée des coordonnées géographiques et renvoi une table pandas des gares les plus proches\n",
    "    lat\n",
    "    pos=(lat,lon)\n",
    "    res=[]\n",
    "    dist=[]\n",
    "    indices=[]\n",
    "    noms=[]\n",
    "    for i in range(len(df_gares)):\n",
    "        station=(df_gares['lat'].iloc[i],df_gares['lon'].iloc[i])\n",
    "        distance=haversine(pos,station)\n",
    "        # Pour toutes les gares de la table, on calcule la distance au point (lat,lon)\n",
    "        if distance<1: #On ne garde que les gares à moins de 1km\n",
    "            name=df_gares['nom'].iloc[i]\n",
    "            # Les gares peuvent apparaître plusieurs fois dans la table si il y a plusieurs lignes \n",
    "            #mais on ne veut garder qu'une seule ligne par gare\n",
    "            if name not in noms:\n",
    "                noms.append(name)\n",
    "                gare=[int(round(distance,3)*1000)] #distance en m\n",
    "                gare.append(name)\n",
    "                gare.append(df_gares['reseau'].iloc[i])\n",
    "                gare.append(df_gares['ligne'].iloc[i])\n",
    "                gare.append(df_gares['lat'].iloc[i])\n",
    "                gare.append(df_gares['lon'].iloc[i])\n",
    "                res.append(gare)\n",
    "            else: #Si on a déjà ajouté la gare dans la table de sortie, il faut donc ajouter la ligne\n",
    "                j=noms.index(name)\n",
    "                if df_gares['reseau'].iloc[i] not in res[j][2]: \n",
    "                    # On ajoute le nom du réseau si il n'y est pas encore \n",
    "                    # Les réseaux sont RER et Métro\n",
    "                    res[j][2]=res[j][2]+\" et \"+df_gares['reseau'].iloc[i]\n",
    "                if df_gares['ligne'].iloc[i] not in res[j][3]:\n",
    "                    # On ajoute le nom ou numéro de la ligne si ils n'y sont pas encore\n",
    "                    # Par exemple 1 ou A\n",
    "                    res[j][3]=str(res[j][3])+\" et \"+str(df_gares['ligne'].iloc[i])\n",
    "    \n",
    "        res=sorted(res, key=lambda gares: gares[0])\n",
    "        # On trie suivant la distance la plus petite\n",
    "        columns=['Distance (m)','Station','Reseau','Ligne','lat','lon']\n",
    "        res2=pd.DataFrame(data=res,columns=columns)\n",
    "        # On crée le DataFrame\n",
    "        res2=res2.drop(columns=['lat','lon'])\n",
    "        # Ces colomnes sont inutiles pour l'utilisateur on les enlève\n",
    "    return(res2)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def next_marches(lat,lon):\n",
    "    # Cette fonction permet de trouver les marchés alimentaires les plus proches\n",
    "    pos=(lon,lat)\n",
    "    dist=[]\n",
    "    jours=[]\n",
    "    noms=[]\n",
    "    for i in range(len(df_marches)):\n",
    "        marche=(df_marches['lat'].iloc[i],df_marches['lon'].iloc[i])\n",
    "        distance=haversine(pos,marche,unit='m')\n",
    "        # Pour tous les marchés de la table, on calcule la distance à la position (lon,lat)\n",
    "        dist.append(int(round(distance,3))) #L'utilisateur n'a que faire de chiffres après la virgule\n",
    "        noms.append(df_marches['Nom court'].iloc[i])\n",
    "        jours.append(df_marches['Jours de tenue'].iloc[i])\n",
    "    res = pd.DataFrame(dist,columns=['Distance (m)'])\n",
    "    res['Nom']=noms\n",
    "    res['Jours de Tenue']=jours\n",
    "    #On crée le DataFrame\n",
    "    res=res.sort_values('Distance (m)')\n",
    "    # On trie par distances croissantes\n",
    "    return(res.iloc[:5]) #On ne garde que les 5 marchés les plus proches,l'utilisateur n'en veut pas plus\n",
    "\n",
    "def appartenance_zone(lon,lat):\n",
    "    # Ce programme prend en entrée la longitude et la latitude et renvoi la position sur le quadrillage\n",
    "    i=int((lat-min_lat)//step_lat)\n",
    "    j=int((lon-min_lon)//step_lon)\n",
    "    return(i,j) \n",
    "\n",
    "def biens_secteur(lon,lat):\n",
    "    # Cette fonction renvoi une version filtrée des biens dans le secteur\n",
    "    i,j=appartenance_zone(lon,lat)\n",
    "    biens=tab[tab['vert']==i]\n",
    "    biens=biens[biens['horiz']==j]\n",
    "    #On ne garde que les biens dans le bon carreau du quadrillage\n",
    "    biens=biens[biens['Prixm2']<20000]\n",
    "    biens=biens[biens['Prixm2']>5000]\n",
    "    # On enlève les valeurs aberrantes (et il y en a ..)\n",
    "    biens['date_mutation'] = pd.to_datetime(biens['date_mutation'], dayfirst=True)\n",
    "    # On passe la colonne date_mutation en format date\n",
    "    return(biens)\n",
    "\n",
    "def Velib(Latitude,Longitude):\n",
    "    # Cette fonction interroge l'API de la ville de Paris et renvoi les stations Velib les plus proches\n",
    "    url='https://opendata.paris.fr/api/records/1.0/search/?dataset=velib-emplacement-des-stations&q=&geofilter.distance='+str(Latitude)+','+str(Longitude)+','+str(400)\n",
    "    L=requests.get(url).json()\n",
    "    cap=[]\n",
    "    name=[]\n",
    "    dist=[]\n",
    "    for i in range(len(L['records'])):\n",
    "        # On récupère les données du dictionnaire\n",
    "        cap.append(str(L['records'][i]['fields']['capacity'])+' Vélibs')\n",
    "        dist.append(int(float(L['records'][i]['fields']['dist'])))\n",
    "        name.append(L['records'][i]['fields']['name'])\n",
    "    res = pd.DataFrame(dist,columns=['Distance (m)']) # On crée le DataFrame\n",
    "    res['Station']=name\n",
    "    res['Capacité']=cap\n",
    "    res=res.sort_values('Distance (m)') #On trie pour avoir les plus proches en premier\n",
    "    return(res.iloc[:5]) #On ne garde que les 5 plus proches\n",
    "\n",
    "def college(Latitude,Longitude):\n",
    "    # Cette fonction interroge l'API de la ville de Paris et renvoi le collège de secteur\n",
    "    # Ce n'est pas forcément le collège le plus proche (carte scolaire)\n",
    "    url='https://opendata.paris.fr/api/records/1.0/search/?dataset=secteurs-scolaires-colleges&q=&sort=annee_scol&facet=id_projet&facet=zone_commune&facet=annee_scol&refine.annee_scol=2021-2022&geofilter.distance='+str(Latitude)+','+str(Longitude)+','+str(10)\n",
    "    L=requests.get(url).json()\n",
    "    # On récupère la première donnée du dictionnaire\n",
    "    # EN effet, on a demandé de trier les données par année scolaire \n",
    "    # On a donc le collège de secteur de l'année 2021-2022 en premier\n",
    "    dist=int(float(L['records'][0]['fields']['dist']))\n",
    "    name=L['records'][0]['fields']['etiquette']+' ('+str(dist)+' m)'\n",
    "    #formatage du nom du collège pour l'affichage \n",
    "    return('Collège: '+name)\n",
    "\n",
    "def elementaire(Latitude,Longitude):\n",
    "    # Cette fonction interroge l'API de la ville de Paris et renvoi l'école élementaire de secteur\n",
    "    # Ce n'est pas forcément l'école élementaire la plus proche (carte scolaire)\n",
    "    url='https://opendata.paris.fr/api/records/1.0/search/?dataset=secteurs-scolaires-ecoles-elementaires&q=&sort=annee_scol&facet=id_projet&facet=zone_commune&facet=annee_scol&refine.annee_scol=2021-2022&geofilter.distance='+str(Latitude)+','+str(Longitude)+','+str(10)\n",
    "    L=requests.get(url).json()\n",
    "    # On récupère la première donnée du dictionnaire\n",
    "    # EN effet, on a demandé de trier les données par année scolaire \n",
    "    # On a donc l'école élementaire de secteur de l'année 2021-2022 en premier\n",
    "    dist=int(float(L['records'][0]['fields']['dist']))\n",
    "    name=L['records'][0]['fields']['etiquette']+' ('+str(dist)+' m)'\n",
    "    #formatage du nom de l'école pour l'affichage \n",
    "    return('Ecole élementaire: '+name)\n",
    "\n",
    "def maternelle(Latitude,Longitude):\n",
    "    # Cette fonction interroge l'API de la ville de Paris et renvoi l'école élementaire de secteur\n",
    "    # Ce n'est pas forcément l'école maternelle la plus proche (carte scolaire)\n",
    "    url='https://opendata.paris.fr/api/records/1.0/search/?dataset=secteurs-scolaires-maternelles&q=&sort=annee_scol&facet=id_projet&facet=zone_commune&facet=annee_scol&refine.annee_scol=2021-2022&geofilter.distance='+str(Latitude)+','+str(Longitude)+','+str(10)\n",
    "    L=requests.get(url).json()\n",
    "    # On récupère la première donnée du dictionnaire\n",
    "    # EN effet, on a demandé de trier les données par année scolaire \n",
    "    # On a donc l'école maternelle de secteur de l'année 2021-2022 en premier\n",
    "    dist=int(float(L['records'][0]['fields']['dist']))\n",
    "    name=L['records'][0]['fields']['etiquette']+' ('+str(dist)+' m)'\n",
    "    #formatage du nom de l'école pour l'affichage \n",
    "    return('Ecole maternelle: '+name)\n",
    "\n",
    "def anomalies(Latitude,Longitude):\n",
    "    bien=(Latitude,Longitude)\n",
    "    # La ville de Paris a mis en place depuis 2014 une application mobile (Dans ma rue) \n",
    "    #Dans cette application, les parisiens peuvent géolocaliser des anomalies (propreté, dysfonctionnements, ...)\n",
    "    # Ces données sont accessibles en temps réel à partir de l'API suivant\n",
    "    # On ne garde que les anomalies situées dans un rayon de 100m\n",
    "    url='https://opendata.paris.fr/api/records/1.0/search/?dataset=dans-ma-rue&q=&rows=10000&sort=type&facet=soustype&facet=type&facet=datedecl&geofilter.distance='+str(Latitude)+','+str(Longitude)+','+str(100)\n",
    "    L=requests.get(url).json()\n",
    "    date=[]\n",
    "    soustype=[]\n",
    "    type_anomalie=[]\n",
    "    for i in range(len(L['records'])):\n",
    "        #on récupère les données du dictionnaire\n",
    "        date.append(L['records'][i]['fields']['datedecl'])\n",
    "        soustype.append(L['records'][i]['fields']['soustype'])\n",
    "        type_anomalie.append(L['records'][i]['fields']['type'])\n",
    "    res = pd.DataFrame(date,columns=['Date'])\n",
    "    res['Description']=soustype\n",
    "    res['Type']=type_anomalie\n",
    "    res['Date']=pd.to_datetime(res['Date'])\n",
    "    #On crée le Dataframe\n",
    "    return(res)\n",
    "\n",
    "\n",
    "\n",
    "def encadrement(Latitude,Longitude,NPieces):\n",
    "    #L'encadrement des loyers est en vigeur à Paris \n",
    "    #Cette fonction permet de récuperer et de tracer les loyers en vigeur \n",
    "    # Ces loyers dépendent de l'époque de construction du bien, du nombre de pièces, de sa localisation et du caractère meublé ou non\n",
    "    bien=(Latitude,Longitude)\n",
    "    url='https://opendata.paris.fr/api/records/1.0/search/?dataset=logement-encadrement-des-loyers&q=&sort=epoque&rows=10000&facet=id_zone&facet=nom_quartier&facet=piece&facet=epoque&facet=meuble_txt&geofilter.distance='+str(Latitude)+','+str(Longitude)+','+str(2)+'&refine.piece='+str(NPieces)\n",
    "    L=requests.get(url).json()\n",
    "    #On interroge l'API et on récupère un dictionnaire \n",
    "    epoque=[]\n",
    "    meuble=[]\n",
    "    max_=[]\n",
    "    min_=[]\n",
    "    type_anomalie=[]\n",
    "    for i in range(len(L['records'])):\n",
    "        epoque.append(L['records'][i]['fields']['epoque'])\n",
    "        meuble.append(L['records'][i]['fields']['meuble_txt'])\n",
    "        max_.append(L['records'][i]['fields']['max'])\n",
    "        min_.append(L['records'][i]['fields']['min'])\n",
    "    res = pd.DataFrame(epoque,columns=['Epoque'])\n",
    "    # On crée un DataFrame\n",
    "    res['Meublé']=meuble\n",
    "    res['Max']=max_\n",
    "    res['Min']=min_\n",
    "    res=res.drop_duplicates()\n",
    "    # On supprime les doublons\n",
    "    Val=res['Max'].to_list()\n",
    "    Meuble=res['Meublé'].to_list()\n",
    "    Prix=res['Max'].to_list()\n",
    "    Epoque=res['Epoque'].to_list()\n",
    "    # On veut créer un boxplot, pour une même caractéristique on a min et max sur la même ligne dans des colonnes différentes\n",
    "    #On veut 1 ligne pour max et 1 ligne pour min \n",
    "    Epoque=Epoque+Epoque\n",
    "    Val=Val+Val\n",
    "    Meuble=Meuble+Meuble\n",
    "    Prix=Prix+res['Min'].to_list()\n",
    "    res = pd.DataFrame(Prix,columns=['Loyer (m2)'])\n",
    "    res['Meublé']=Meuble\n",
    "    res['Epoque de construction']=Epoque\n",
    "    # On crée le boxplot \n",
    "    fig = px.box(res, x=\"Epoque de construction\", y=\"Loyer (m2)\", color=\"Meublé\")\n",
    "    return(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions pour tracer des figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_temporel_anomalies(df):\n",
    "    # Cette fonction représente l'évolution temporelle des anomalies depuis 2018\n",
    "    df=df[df['Date']>'2018-01-01']\n",
    "    df=df.groupby(['Type','Date']).count()\n",
    "    # On ne garde qu'une seule ligne par type et date contenant le nombre d'anomalies (d'ou le count())\n",
    "    df['Signalements']=df['Description']\n",
    "    df=df.reset_index(level=[0,1])\n",
    "    fig=px.scatter(df,x='Date',y='Signalements',color='Type')\n",
    "    # Renvoi une figure \n",
    "    return(fig)\n",
    "\n",
    "def plot_repartition_anomalies(df):\n",
    "    #Cette fonction permet de créer une figure de la répartition des anomalies (par catégorie et groupe )depuis 2018\n",
    "    df=df[df['Date']>'2018-01-01']\n",
    "    df=df.groupby(['Type','Description']).count()\n",
    "    df['Nombre']=df['Date']\n",
    "    df=df.sort_values('Nombre',ascending=False).head(15)\n",
    "    # On enlève les anomalies avec peu d'occurences en triant et avec le .head(15)\n",
    "    df=df.reset_index(level=[0,1])\n",
    "    fig =px.sunburst(df,path=['Type','Description'],values='Nombre')\n",
    "    # Création de la figure\n",
    "    return(fig)\n",
    "\n",
    "def plot_temporel(tab):\n",
    "    #Et on retire les colonnes inutiles\n",
    "    \n",
    "    tab2=tab.drop(columns=['valeur_fonciere',\n",
    "       'code_postal', 'surface_reelle_bati', 'nombre_pieces_principales',\n",
    "       'surface_terrain', 'longitude', 'latitude','groupes', 'vert', 'horiz', 'Unnamed: 0', 'label'])\n",
    "    \n",
    "    #On trie par date de vente croissante, et on met la date en index du dataframe tab2\n",
    "    \n",
    "    tab2['date_mutation'] = pd.to_datetime(tab2['date_mutation'],dayfirst=True)\n",
    "    tab2.sort_values('date_mutation',inplace=True)\n",
    "    tab2.set_index('date_mutation',inplace=True)\n",
    "    tab2.index = pd.to_datetime(tab2.index, dayfirst=True)\n",
    "    \n",
    "    #On calcule la moyenne glissante du prix m² sur tab2, que l'on stocke dans tab_roll\n",
    "    \n",
    "    tab_roll=tab2.rolling(len(tab)//5, win_type='triang',center=False).mean()\n",
    "    \n",
    "    #Réindexation en vue d'ajouter des dates à tab2\n",
    "    \n",
    "    ix = pd.DataFrame(index = pd.date_range('2014-01-01','2022-01-01', freq='D'))\n",
    "    tab2 = pd.merge(ix, tab2, left_index = True, right_index = True, how = 'left')\n",
    "    \n",
    "    #On applique predict_temp pour remplir les dates nouvellement ajoutées (1 an)\n",
    "    \n",
    "    tab2.iloc[-366:-1]['Prixm2'] = predict_temp(tab, date(2022, 1, 1))\n",
    "    \n",
    "    #On trace les ventes (fig2), la moyenne glissante (fig3) et les anticipations sur 1 an (fig4) avec plotly\n",
    "    fig2=px.scatter(tab,x='date_mutation',y='Prixm2')\n",
    "    fig3=px.line(tab_roll,x=tab_roll.index,y='Prixm2')\n",
    "    fig4=px.line(tab2.iloc[-366:-1],x=tab2.iloc[-366:-1].index,y='Prixm2')\n",
    "    fig3.update_traces(line_color='#DC143C')\n",
    "    fig4.update_traces(line_color='#DC143C')\n",
    "    fig3 = go.Figure(data=fig2.data + fig3.data + fig4.data)\n",
    "    return(fig3)\n",
    "\n",
    "def plot_map(tab,Latitude,Longitude):\n",
    "    # Cette fonction permet de tracer une carte open street map\n",
    "    # Cette carte contient toutes les ventes immoblières non aberrantes du secteur\n",
    "    # Elle est centrée sur l'adresse saisie (Latitude et Longitude)\n",
    "    fig = px.scatter_mapbox(data_frame=tab,lon=\"longitude\",lat=\"latitude\",hover_name='label',zoom=16,height=0,center={'lat':Latitude,'lon':Longitude})\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "    fig.update_layout(margin={\"r\":3,\"t\":3,\"l\":3,\"b\":3})\n",
    "    fig.update_traces(marker=dict(size=15,opacity=0.9))\n",
    "    return(fig)\n",
    "\n",
    "def plot_Parism2(tab):\n",
    "    # Cette fonction trace une carte de Paris avec des points indiquant le prix moyen au m2\n",
    "    # Il y a un point par zone du quadrillage\n",
    "    # Le point est placé sur la position moyenne des biens du secteur \n",
    "    #Cela permet de ne pas avoir de points au milieu de la Seine par exemple\n",
    "    tab=tab[tab['Prixm2']<20000]\n",
    "    tab=tab[tab['Prixm2']>5000]\n",
    "    # On élimine les valeurs aberrantes \n",
    "    fig = px.scatter_mapbox(data_frame=tab.groupby(['vert','horiz']).mean(),lon=\"longitude\",hover_name=\"Prixm2\",color='Prixm2',lat=\"latitude\",zoom=11,height=0,center={'lon':2.342984676361084,'lat':48.862272686497576})\n",
    "    #On trace la figure\n",
    "    fig.update_layout(mapbox_style=\"carto-positron\")\n",
    "    fig.update_layout(margin={\"r\":3,\"t\":3,\"l\":3,\"b\":3})\n",
    "    fig.update_traces(marker=dict(size=17,opacity=0.9))\n",
    "    return(fig)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\arima_model.py:472: FutureWarning:\n",
      "\n",
      "\n",
      "statsmodels.tsa.arima_model.ARMA and statsmodels.tsa.arima_model.ARIMA have\n",
      "been deprecated in favor of statsmodels.tsa.arima.model.ARIMA (note the .\n",
      "between arima and model) and\n",
      "statsmodels.tsa.SARIMAX. These will be removed after the 0.12 release.\n",
      "\n",
      "statsmodels.tsa.arima.model.ARIMA makes use of the statespace framework and\n",
      "is both well tested and maintained.\n",
      "\n",
      "To silence this warning and continue using ARMA and ARIMA until they are\n",
      "removed, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARMA',\n",
      "                        FutureWarning)\n",
      "warnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARIMA',\n",
      "                        FutureWarning)\n",
      "\n",
      "\n",
      "C:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:581: ValueWarning:\n",
      "\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "\n",
      "C:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:581: ValueWarning:\n",
      "\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "\n",
      "<ipython-input-4-51172fa0cdd3>:49: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cette partie permet d'initialiser l'interface graphique \n",
    "# On choisi une position arbitraire dans Paris\n",
    "# On crée les figures et les tables\n",
    "Latitude,Longitude,nom=coordo('','','55 rue du Faubourg St Honoré',75008)\n",
    "prov=biens_secteur(Longitude,Latitude)\n",
    "data_metro=next_gares(Latitude,Longitude).iloc[:5].to_dict(orient='records')\n",
    "data_marche=next_marches(Latitude,Longitude).to_dict(orient='records')\n",
    "data_velib=Velib(Latitude,Longitude).to_dict(orient='records')\n",
    "fig=plot_map(prov,Latitude, Longitude)\n",
    "fig2=plot_temporel(prov)\n",
    "fig0=plot_Parism2(tab[tab['date_mutation']>='2020-01-01'])\n",
    "\n",
    "tab_anomalies=anomalies(Latitude,Longitude)\n",
    "fig_rep_anomalies=plot_repartition_anomalies(tab_anomalies)\n",
    "fig_temp_anomalies=plot_temporel_anomalies(tab_anomalies)\n",
    "encadrement_loyers=encadrement(Latitude,Longitude,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interface Graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global click_button\n",
    "click_button=0\n",
    "colors = {\n",
    "    'background': '#99CCFF',\n",
    "    'title': '#CC3333',\n",
    "    'text':'#1E90FF'\n",
    "}\n",
    "app = JupyterDash(__name__)\n",
    "# Dash combine de l'HTML et des composants Dash\n",
    "app.layout = html.Div([\n",
    "    \n",
    "    html.H1(\n",
    "        children='Console Immobilière',\n",
    "        style={\n",
    "            'textAlign': 'left',\n",
    "            'color': colors['title'],\n",
    "            'background-color': colors['background'],\n",
    "            'font-family':'Optima'\n",
    "        }\n",
    "    ),\n",
    "    html.H2(\n",
    "        children='Simulateur des prix des biens immobiliers à Paris',\n",
    "        style={\n",
    "            'textAlign': 'left',\n",
    "            'color': colors['text']\n",
    "        }\n",
    "    ),\n",
    "    html.Div([\n",
    "        html.H4(\"Code Postal:\"),\n",
    "        #Zone de texte initialisée à 75008\n",
    "        html.Div([\" \",\n",
    "                  dcc.Input(id='code_postal', value='75008', type='text')]),\n",
    "        html.H4(\"Nombre de pièces :\"),\n",
    "        #Slider initialisé à 3\n",
    "        dcc.Slider(id='piece',min=1,max=9,marks={i: '{}'.format(i) for i in range(0,10)},value=3),  \n",
    "        html.H4(\"Adresse:\"),\n",
    "        #Zone de texte initialisée à 75008\n",
    "        html.Div([\" \",\n",
    "                  dcc.Input(id='rue', value='55 rue du Faubourg St Honoré', type='text')]),\n",
    "        html.H4('Surface'),\n",
    "        #SLider initialisé à 50\n",
    "        dcc.Slider(id='surface',\n",
    "            min=0,\n",
    "            max=400,\n",
    "            step=10,\n",
    "            value=50,\n",
    "            marks={\n",
    "                0:\"0\",\n",
    "                20:\"20\",\n",
    "                30:\"30\",\n",
    "                40:\"40\",\n",
    "                50:\"50\",\n",
    "                75:\"75\",\n",
    "                100:\"100\",\n",
    "                120:\"120\",\n",
    "                150:\"150\",\n",
    "                200:\"200\",\n",
    "                250:\"250\",\n",
    "                300:\"300\",\n",
    "                400:\"400\"\n",
    "            }\n",
    "        ),\n",
    "        \n",
    "       \n",
    "    ],style={'columnCount': 2}),\n",
    "        \n",
    "    html.Div([\n",
    "        html.Br(),\n",
    "        html.Button('Estimer', id='submit-val', n_clicks=0,style={'textAlign': 'center'}),\n",
    "        html.H3(id='text_choix',children=' Sélectionnez les caractéristiques de votre bien',style={'textAlign': 'center'}), \n",
    "        #Loading pour signifier à l'utilisateur de patienter\n",
    "        dcc.Loading(\n",
    "            id=\"loading-1\",\n",
    "            type=\"circle\",\n",
    "            color=colors['text'],\n",
    "            children=html.Div(id=\"loading-output-1\")\n",
    "        ),\n",
    "        \n",
    "        \n",
    "    ]),\n",
    "    html.H2(\n",
    "        id='estimation',\n",
    "        children=' ',\n",
    "        style={\n",
    "            'textAlign': 'center',\n",
    "            'color': colors['text']\n",
    "        }\n",
    "    ),\n",
    "    html.H3(\n",
    "        id='estimation2',\n",
    "        children='',\n",
    "        style={\n",
    "            'textAlign': 'center',\n",
    "            'color': colors['text']\n",
    "        }\n",
    "    ),\n",
    "    dcc.Graph(id=\"Biens\",figure=fig),\n",
    "    html.Div([\n",
    "        \n",
    "        html.H3(children='Evolution des prix au m2 sur le secteur',style={'textAlign': 'left','color':colors['text']}),\n",
    "        dcc.Graph(id=\"temporel\",figure=fig2),\n",
    "        html.H3(children='Prix au m2 dans Paris en 2020',style={'textAlign': 'left','color':colors['text']}),\n",
    "        dcc.Graph(id=\"m2_Paris\",figure=fig0),\n",
    "        \n",
    "        \n",
    "    ],style={'columnCount': 2}), \n",
    "    html.Div([\n",
    "        html.H3(children='Transports à proximité',style={'textAlign': 'left','color':colors['text']}),\n",
    "    ],style={'columnCount': 1}),  \n",
    "    html.Div([\n",
    "        html.H4(children='Métro et RER',style={'textAlign': 'left'}),\n",
    "        dash_table.DataTable(\n",
    "    id='metro',\n",
    "    columns=[\n",
    "    {'name': 'Distance (m)', 'id': 'Distance (m)'},\n",
    "    {'name': 'Station', 'id': 'Station'},\n",
    "    {'name': 'Reseau', 'id': 'Reseau'},\n",
    "    {'name': 'Ligne', 'id': 'Ligne'}],\n",
    "    data=data_metro),\n",
    "        html.H4(children='Vélib',style={'textAlign': 'left'}),\n",
    "        dash_table.DataTable(\n",
    "    id='velib',\n",
    "    columns=[\n",
    "    {'name': 'Distance (m)', 'id': 'Distance (m)'},\n",
    "    {'name': 'Station', 'id': 'Station'},\n",
    "    {'name': 'Capacité', 'id': 'Capacité'},\n",
    "    ],\n",
    "    data=data_velib),\n",
    "    ],style={'columnCount': 2}),\n",
    "    html.Div([\n",
    "        html.H3(children='Carte scolaire',style={'textAlign': 'left','color':colors['text']}),\n",
    "        html.H4(id='college',children='Collège de Secteur',style={'textAlign': 'left'}),\n",
    "        html.H4(id='primaire',children='Ecole primaire du secteur',style={'textAlign': 'left'}),\n",
    "        html.H4(id='maternelle',children='Ecole maternelle du secteur',style={'textAlign': 'left'}),\n",
    "        html.H3(children='Marchés alimentaires à proximité',style={'textAlign': 'left','color':colors['text']}),\n",
    "        dash_table.DataTable(\n",
    "    id='marche',\n",
    "    columns=[\n",
    "    {'name': 'Distance (m)', 'id': 'Distance (m)'},\n",
    "    {'name': 'Nom', 'id': 'Nom'},\n",
    "    {'name': 'Jours de Tenue', 'id': 'Jours de Tenue'},\n",
    "    ],\n",
    "    data=data_marche),\n",
    "        html.H3(children='Anomalies signalées dans un rayon de 100m (Application Dans Ma Rue)',style={'textAlign': 'left','color':colors['text']}), \n",
    "    ],style={'columnCount': 1}), \n",
    "    html.Div([\n",
    "        html.H3(children='Répartition depuis 2018',style={'textAlign': 'left'}),\n",
    "        dcc.Graph(id=\"nbre_anomalies\",figure=fig_rep_anomalies),\n",
    "        html.H3(children='Evolution depuis 2018',style={'textAlign': 'left'}),\n",
    "        dcc.Graph(id=\"temp_anomalies\",figure=fig_temp_anomalies),\n",
    "    ],style={'columnCount': 2}), \n",
    "    html.Div([\n",
    "        html.H3(children='Encadrement des loyers dans le secteur',style={'textAlign': 'left','color':colors['text']}), \n",
    "        dcc.Graph(id=\"encadrement\",figure=encadrement_loyers),\n",
    "    ],style={'columnCount': 1}), \n",
    "])\n",
    "# La call back permet d'updater les figures et tables en fonction des Input (action utilisateur) et State (état du composant)\n",
    "@app.callback(\n",
    "    \n",
    "    Output(component_id=\"loading-output-1\", component_property=\"children\"),\n",
    "    Output(component_id='text_choix', component_property='children'),\n",
    "    Output(component_id=\"Biens\",component_property='figure'),\n",
    "    Output(component_id=\"temporel\",component_property='figure'),\n",
    "    Output(component_id=\"estimation\",component_property='children'),\n",
    "    Output(component_id=\"estimation2\",component_property='children'),\n",
    "    Output(component_id='metro', component_property='data'),\n",
    "    Output(component_id='velib', component_property='data'),\n",
    "    Output(component_id='college', component_property='children'),\n",
    "    Output(component_id='primaire', component_property='children'),\n",
    "    Output(component_id='maternelle', component_property='children'),\n",
    "    Output(component_id='marche', component_property='data'),\n",
    "    Output(component_id='nbre_anomalies', component_property='figure'),\n",
    "    Output(component_id='temp_anomalies', component_property='figure'),\n",
    "    Output(component_id='encadrement', component_property='figure'),\n",
    "    Input(component_id='submit-val',component_property='n_clicks'),\n",
    "    State(component_id='code_postal', component_property='value'),\n",
    "    State(component_id='surface', component_property='value'),\n",
    "    State(component_id='piece', component_property='value'),\n",
    "    State(component_id='rue', component_property='value')\n",
    "    \n",
    ")\n",
    "def update_output_div(click,code_postal,surface,piece,rue):\n",
    "    # Cette fonction prend en entrée les Inupt et State et renvoi ce qui va updater les Output\n",
    "    global click_button\n",
    "    if click>click_button:\n",
    "        click_button=click\n",
    "        Lat,Lon,Name=coordo('',' ',rue,code_postal)\n",
    "        text=\" Appartement d'une surface de \"+str(surface)+\"m2 au \"\n",
    "        text=text+Name\n",
    "        tab=biens_secteur(Lon,Lat)\n",
    "        fig=plot_map(tab,Lat,Lon)\n",
    "        fig2=plot_temporel(tab)\n",
    "        prediction=round(pred_secteurs(tab[tab['date_mutation']>='2019-01-01'], bon_format(piece, surface))[0],0)\n",
    "        prediction_m2=round(float(prediction)/surface,2)\n",
    "        data = next_gares(Lat,Lon).iloc[:5].to_dict(orient='records')\n",
    "        data1=Velib(Lat,Lon).to_dict(orient='records')\n",
    "        data2 = next_marches(Lat,Lon).iloc[:5].to_dict(orient='records')\n",
    "        tab_anomalies=anomalies(Lat,Lon)\n",
    "        fig_rep_anomalies=plot_repartition_anomalies(tab_anomalies)\n",
    "        fig_temp_anomalies=plot_temporel_anomalies(tab_anomalies)\n",
    "        fig_encadrement_loyers=encadrement(Lat,Lon,piece)\n",
    "        return('','{}'.format(text),fig,fig2,'Estimation de votre bien: {}'.format(format_prix(prediction)),'Prix au m2: {}'.format(format_prix(prediction_m2)),data,data1,college(Lat,Lon),elementaire(Lat,Lon),maternelle(Lat,Lon),data2,fig_rep_anomalies,fig_temp_anomalies,fig_encadrement_loyers)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(mode='external',port=8050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctionnalité abandonnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcs(Latitude,Longitude):\n",
    "    url='https://opendata.paris.fr/api/records/1.0/search/?dataset=espaces_verts&q=&sort=-nom_ev&facet=type_ev&facet=categorie&facet=adresse_codepostal&facet=ouvert_ferme&geofilter.distance='+str(Latitude)+','+str(Longitude)+','+str(300)\n",
    "    L=requests.get(url).json()\n",
    "    cat=[]\n",
    "    name=[]\n",
    "    dist=[]\n",
    "    for i in range(len(L['records'])):\n",
    "        cat.append(L['records'][i]['fields']['type_ev'])\n",
    "        name.append(L['records'][i]['fields']['nom_ev'])\n",
    "        dist.append(L['records'][i]['fields']['dist'])\n",
    "    res = pd.DataFrame(dist,columns=['Distance (m)'])\n",
    "    res['Catégorie']=cat\n",
    "    res['Nom']=name\n",
    "    return(res)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance (m)</th>\n",
       "      <th>Catégorie</th>\n",
       "      <th>Nom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Infinity</td>\n",
       "      <td>Murs végétalisés</td>\n",
       "      <td>JARDINIERE VERTICALE DU 11 RUE DE COURCELLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Infinity</td>\n",
       "      <td>Décorations sur la voie publique</td>\n",
       "      <td>JARDINIERE SAINT-PHILIPPE DU ROULE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Infinity</td>\n",
       "      <td>Jardinets décoratifs</td>\n",
       "      <td>JARDINET DU CHEVET SAINT PHILIPPE DU ROULE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Distance (m)                         Catégorie  \\\n",
       "0     Infinity                  Murs végétalisés   \n",
       "1     Infinity  Décorations sur la voie publique   \n",
       "2     Infinity              Jardinets décoratifs   \n",
       "\n",
       "                                            Nom  \n",
       "0  JARDINIERE VERTICALE DU 11 RUE DE COURCELLES  \n",
       "1            JARDINIERE SAINT-PHILIPPE DU ROULE  \n",
       "2    JARDINET DU CHEVET SAINT PHILIPPE DU ROULE  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\arima_model.py:472: FutureWarning:\n",
      "\n",
      "\n",
      "statsmodels.tsa.arima_model.ARMA and statsmodels.tsa.arima_model.ARIMA have\n",
      "been deprecated in favor of statsmodels.tsa.arima.model.ARIMA (note the .\n",
      "between arima and model) and\n",
      "statsmodels.tsa.SARIMAX. These will be removed after the 0.12 release.\n",
      "\n",
      "statsmodels.tsa.arima.model.ARIMA makes use of the statespace framework and\n",
      "is both well tested and maintained.\n",
      "\n",
      "To silence this warning and continue using ARMA and ARIMA until they are\n",
      "removed, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARMA',\n",
      "                        FutureWarning)\n",
      "warnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARIMA',\n",
      "                        FutureWarning)\n",
      "\n",
      "\n",
      "C:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:581: ValueWarning:\n",
      "\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "\n",
      "C:\\Users\\Paul\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:581: ValueWarning:\n",
      "\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "\n",
      "<ipython-input-4-51172fa0cdd3>:49: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298, 2)\n",
      "(298,)\n",
      "[-2618.47594699 12460.09314513]\n",
      "87.59878625124254\n"
     ]
    }
   ],
   "source": [
    "parcs(Latitude,Longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctionnalité abandonée car la distance est tojours égale à Infinity. L'API fonctionne mal. On pourrait bien sûr recalculer la distance avec haversine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
